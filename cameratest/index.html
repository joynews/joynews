<!doctype html>
<html lang="en">
	<head>
		<title>Face tracker</title>
		<meta charset="utf-8">
		<link href="/styles/bootstrap.min.css" rel="stylesheet" type="text/css">
		<style>
			@import url(https://fonts.googleapis.com/css?family=Lato:300italic,700italic,300,700);

			body {
				font-family: 'Lato';
				background-color: #f0f0f0;
				margin: 0px auto;
				max-width: 1150px;
			}

			#videoel {
				-o-transform : scaleX(-1);
				-webkit-transform : scaleX(-1);
				transform : scaleX(-1);
				-ms-filter : fliph; /*IE*/
				filter : fliph; /*IE*/

				width : 600px;
				height : 450px;
        display: none;
			}

			#container {
				position : relative;
				width : 370px;
				/*margin : 0px auto;*/
			}

			#content {
				margin-top : 50px;
				margin-left : auto;
				margin-right : auto;
				max-width: 600px;
			}

			h2 {
				font-weight : 400;
			}

			.btn {
				font-family: 'Lato';
				font-size: 16px;
			}

			#controls {
				text-align : center;
			}

			#emotion_container {
				width: 600px;
			}

			#emotion_icons {
				height: 50px;
				padding-left: 40px;
			}

			.emotion_icon {
				width : 40px;
				height : 40px;
				margin-top: 5px;
				/*margin-left : 13px;*/
				margin-left : 35px;
			}

			#emotion_chart, #emotion_icons {
				margin: 0 auto;
				width : 400px;
			}

			#icon1, #icon2, #icon3, #icon4, #icon5, #icon6 {
				visibility : hidden;
			}

			/* d3 */
			.bar {
				fill : steelblue;
				fill-opacity : .9;
			}

		</style>
		<script>
			// getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
			if (window.location.protocol == "file:") {
				alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
			} else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:"){
				window.location.protocol = "https";
			}
		</script>
		<script type="text/javascript">

			var _gaq = _gaq || [];
			_gaq.push(['_setAccount', 'UA-32642923-1']);
			_gaq.push(['_trackPageview']);

			(function() {
				var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
				ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
				var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
			})();

		</script>
	</head>
	<body>
		<script src="/js/utils.js"></script>
		<script src="/js/clmtrackr.js"></script>
		<script src="/models/model_pca_20_svm_emotionDetection.js"></script>
		<script src="/js/emotion_classifier.js"></script>
		<script src="/js/emotionmodel.js"></script>
		<div id="content">
			<h2>Emotion detection example</h2>
			<p>This a test of emotion detection based on parameter output from <em>clmtrackr</em>.</p>
			<div id="container">
				<video id="videoel" width="400" height="300" preload="auto" loop></video>
			</div>
			<div id="controls">
				<input class="btn" type="button" value="wait, loading video" disabled="disabled" onclick="startTracking()" id="startbutton"></input>
			</div>
			<script>
				var vid = document.getElementById('videoel');

				/********** check and set up video/webcam **********/

				function enablestart() {
					var startbutton = document.getElementById('startbutton');
					startbutton.value = "start";
					startbutton.disabled = null;

					vid.play();
				}

				/*var insertAltVideo = function(video) {
					if (supports_video()) {
						if (supports_ogg_theora_video()) {
							video.src = "/media/cap12_edit.ogv";
						} else if (supports_h264_baseline_video()) {
							video.src = "/media/cap12_edit.mp4";
						} else {
							return false;
						}
						//video.play();
						return true;
					} else return false;
				}*/
				navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
				window.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;

				// check for camerasupport
				if (navigator.getUserMedia) {
					// set up stream

					var videoSelector = {video : true};
					if (window.navigator.appVersion.match(/Chrome\/(.*?) /)) {
						var chromeVersion = parseInt(window.navigator.appVersion.match(/Chrome\/(\d+)\./)[1], 10);
						if (chromeVersion < 20) {
							videoSelector = "video";
						}
					};

					navigator.getUserMedia(videoSelector, function( stream ) {
						if (vid.mozCaptureStream) {
							vid.mozSrcObject = stream;
						} else {
							vid.src = (window.URL && window.URL.createObjectURL(stream)) || stream;
						}
						vid.play();
					}, function() {
						//insertAltVideo(vid);
						alert("There was some problem trying to fetch video from your webcam. If you have a webcam, please make sure to accept when the browser asks for access to your webcam.");
					});
				} else {
					//insertAltVideo(vid);
					alert("This demo depends on getUserMedia, which your browser does not seem to support. :(");
				}

				vid.addEventListener('canplay', enablestart, false);

				/*********** setup of emotion detection *************/

				var ctrack = new clm.tracker({useWebGL : true});
				ctrack.init(pModel);


        /*
         * We use exponential rolling decay for emotions, to reduce impact of noise
         * from the classifier.
         */
        var HALF_LIFE = 1000;
        var start = null;
        var last = null;
        var emotions = {};

        /*
         * Storing this allows us to stop the animation loop on demand.
         */
        var animRequest = null;

				function startTracking() {
          if (animRequest === null) {
            ctrack.start(vid);
            start = null;
            last = null;
            emotions = {};
            animRequest = requestAnimFrame(loop);

            var startbutton = document.getElementById('startbutton');
  					startbutton.value = "stop";
            startbutton.onclick = stopTracking;
          }

				}

        function stopTracking() {
          if (animRequest !== null) {
            ctrack.stop();
            cancelRequestAnimFrame(animRequest);
            animRequest = null;

            var startbutton = document.getElementById('startbutton');
  					startbutton.value = "start";
            startbutton.onclick = startTracking;
          }
        }

        function getEmotionMap(er) {
          var emotions = {};
          er.forEach(function(entry) {
            emotions[entry.emotion] = entry.value;
          });
          return emotions;
        }

        function getMaxEmotion(emotions) {
          var maxEmotion = null;
          var maxValue = -Infinity;
          for (var emotion in emotions) {
            if (emotions.hasOwnProperty(emotion) && emotions[emotion] > maxValue) {
              maxEmotion = emotion;
              maxValue = emotions[emotion];
            }
          }
          return maxEmotion;
        }

        function blendEmotions(e1, e2, elapsed) {
          var factor = Math.pow(0.5, elapsed / HALF_LIFE);
          for (var emotion in e1) {
            if (!e1.hasOwnProperty(emotion)) {
              continue;
            }
            if (e2.hasOwnProperty(emotion)) {
              e1[emotion] = e1[emotion] * (1.0 - factor) + e2[emotion] * factor;
            }
          }
          for (var emotion in e2) {
            if (e2.hasOwnProperty(emotion) && !e1.hasOwnProperty(emotion)) {
              e1[emotion] = e2[emotion];
            }
          }
          return e1;
        }

				function loop(timestamp) {
					animRequest = requestAnimFrame(loop);
					var cp = ctrack.getCurrentParameters();

					var er = ec.meanPredict(cp);
          if (!er) {
            return;
          }

          var nextEmotions = getEmotionMap(er);
          if (start === null) {
            start = timestamp;
            emotions = nextEmotions;
          } else {
            var elapsed = timestamp - last;
            emotions = blendEmotions(emotions, nextEmotions, elapsed);
          }
          console.log(getMaxEmotion(emotions));
          last = timestamp;
				}

				var ec = new emotionClassifier();
				ec.init(emotionModel);
				var emotionData = ec.getBlank();
			</script>
		</div>
	</body>
</html>
